{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Programming - SW Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02: Simple Deep Neural Network\n",
    "## Exercise: Predicting MNIST Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhC9a_u5Ta4u"
   },
   "source": [
    "### Prepare Mini-MNIST Dataset from Scikit-Learn\n",
    "http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MboBxtwcTa41"
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "# digits.data from sklearn contains 1797 images of 8x8 pixels\n",
    "# Each image has a hand-written digit\n",
    "digits_df = digits.images.reshape((len(digits.target), -1))\n",
    "digits_tf = digits.target\n",
    "\n",
    "# Splitting dataframe into train & test\n",
    "X_train_org, X_test_org, y_train_num, y_test = train_test_split(digits_df, digits_tf, test_size= 0.20, random_state=101)\n",
    "\n",
    "# Digits data has range of [0,16], which often lead too big exponential values\n",
    "# so make them normal distribution of [0,1] with the sklearn package, or you can just divide them by 16\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train_org)\n",
    "X_test = sc.transform(X_test_org)\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "# Transform Nx1 Y vector into Nx10 answer vector, so that we can perform one-to-all classification\n",
    "y_train = np.zeros((y_train_num.shape[0],10))\n",
    "for i in range(n_classes):\n",
    "    y_train[:,i] = (y_train_num == i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function can be defined as:\n",
    "\n",
    "$$ \\text{sigmoid}(x) = {1 \\over {1 + e^{-x}}} = {e^{x} \\over {1 + e^{x}}} $$\n",
    "\n",
    "Sigmoid function takes numbers between $[-\\infty, \\infty]$ and gives back numbers between $[0, 1]$.<br>\n",
    "However, the corresponding numpy implementation warns overflow for large negative inputs.<br>\n",
    "The function below is the implementation of numerically stable sigmoid. Complete the code **without using `if` statement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySigmoid(x):\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    positive = (x>=0)                            # boolean array of positive numbers\n",
    "    x_p = x[positive]                            # array of positive x\n",
    "    x_n = x[~positive]                           # array of negative x\n",
    "    x[positive] = 1/(1+np.exp(-x_p))             # apply sigmoid function for x_p\n",
    "    x[~positive] = np.exp(x_n)/(1+np.exp(x_n))   # apply sigmoid function for x_n\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. , 0. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySigmoid(np.array([0.0, 1000.0, -1000.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax function can be defined as:\n",
    "\n",
    "$$ \\text{softmax}(x_i) = {e^{x_i} \\over {\\sum_{k=1}^n e^{x_k}}} $$\n",
    "\n",
    "Softmax function also takes numbers between $[-\\infty, \\infty]$ and gives back numbers between $[0, 1]$.<br>\n",
    "Therefore, this function has the same overflow problem for large positive inputs.<br>\n",
    "The function below is the implementation of numerically stable softmax.<br>\n",
    "You can make the softmax stable by multiplying $e^{-M}$ to both numerator and denominator. <br>\n",
    "Complete the code **without using `if` statement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define softmax. Assume (b, s)\n",
    "def mySoftmax(x):\n",
    "    ### START CODE HERE ###\n",
    "    x = x - np.max(x, axis=-1,keepdims=True)        # make x sufficiently small\n",
    "    x = np.exp(x)                                   # execute exponential function\n",
    "    x = x / np.sum(x, axis=-1,keepdims=True)        # calculate softmax\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySoftmax(np.array([0.0, 1000.0, -1000.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1437, 64)\n",
      "(1437, 10)\n",
      "[ 0.  0.  0.  9. 16.  6.  0.  0.  0.  0.  4. 15.  6. 15.  0.  0.  0.  0.\n",
      "  8. 11.  9. 11.  0.  0.  0.  0.  8. 16. 14.  2.  0.  0.  0.  0. 11. 16.\n",
      " 13.  0.  0.  0.  0.  6. 14.  2. 12.  9.  0.  0.  0.  5. 16. 11.  5. 13.\n",
      "  4.  0.  0.  0.  3.  8. 13. 16.  9.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is 4\n"
     ]
    }
   ],
   "source": [
    "print(digits_df.shape) # all_data\n",
    "print(X_train.shape)   # train_data\n",
    "print(y_train.shape)   # train_label\n",
    "print(X_train_org[0])  #first train data's pixel value\n",
    "\n",
    "idx = np.random.randint(X_train.shape[0]) #random extracting sample\n",
    "dimage = X_train_org[idx].reshape((8,8))  #convert 1d data sample to 2d image sample\n",
    "plt.figure(figsize=(2, 2))                #create figure\n",
    "plt.gray()                                #grayscale\n",
    "plt.matshow(dimage, fignum=1)             #display image to figure\n",
    "plt.show()                                #show\n",
    "print('The number is', y_train_num[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple DNN for Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDenseLayer:\n",
    "    def __init__(self, n_out, n_in):\n",
    "        self.wegt = np.empty((n_out, n_in)) #weight\n",
    "        self.bias = np.zeros((n_out))       #bias\n",
    "        self.saved_x = None     # store x to use while backpropagation\n",
    "\n",
    "    def forward(self, x):       # (b, i)\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        self.saved_x = x     # keep it for backward\n",
    "        x_lin = (self.wegt @ x.T).T + self.bias           # Linear Prediction\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        return x_lin\n",
    "\n",
    "    def backward(self, x, x_in):  # x = dJ/dz (b, c)\n",
    "        assert np.array_equal(self.saved_x, x_in), print('x_in does not equal to input X.')\n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        dw = (x.T @ x_in)            # Gradients for weights\n",
    "        db = np.sum(x,axis=0)        # Gradients for biases\n",
    "        wdJdz = x @ self.wegt        # Propagation for lower layer\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        return dw, db, wdJdz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3.23890168  3.05091188 -3.32627831]\n",
      "  [ 0.388114    3.36724875  1.06158492]\n",
      "  [ 3.10267869  1.87570497 -1.8326582 ]]\n",
      "\n",
      " [[-7.60581826  2.36703751 -1.16423539]\n",
      "  [ 3.48035012  2.41940644 -0.13917734]\n",
      "  [ 1.20541315  2.07585619 -1.5435161 ]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "tmp = myDenseLayer(3,5)\n",
    "tmp.wegt = np.random.randn(3,5)\n",
    "tmp.bias = np.random.randn(3)\n",
    "\n",
    "print(tmp.forward(np.random.randn(2,5,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Outputs**\n",
    "\n",
    "```\n",
    "[[[ 3.23890168  3.05091188 -3.32627831]\n",
    "  [ 0.388114    3.36724875  1.06158492]\n",
    "  [ 3.10267869  1.87570497 -1.8326582 ]]\n",
    "\n",
    " [[-7.60581826  2.36703751 -1.16423539]\n",
    "  [ 3.48035012  2.41940644 -0.13917734]\n",
    "  [ 1.20541315  2.07585619 -1.5435161 ]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Backpropagation of Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dJdz_sigmoid(wdJdz_upper, az):\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    dJdz = wdJdz_upper * (1.0-az) * az            # backpropagation through activation function\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return dJdz\n",
    "\n",
    "def dJdz_softmax(y_hat, y):\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    dJdz = (y_hat - y)            # backpropagation through activation function\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return dJdz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.90531647 -0.64834065 -1.89126428]\n",
      "[ 0.53948992 -0.29540078 -1.55749236]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "print(dJdz_sigmoid(np.random.randn(3),np.random.randn(3)))\n",
    "print(dJdz_softmax(np.random.randn(3),np.random.randn(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Outputs**\n",
    "\n",
    "```\n",
    "[-4.90531647 -0.64834065 -1.89126428]\n",
    "[ 0.53948992 -0.29540078 -1.55749236]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Training Functions<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_forward(l1, l2, l3, X_in):\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    a_1 = mySigmoid(l1.forward(X_in))                    # first stage forward\n",
    "    a_2 = mySigmoid(l2.forward(a_1))                    # second stage forward\n",
    "    a_3 = mySoftmax(l3.forward(a_2))                    # third stage forward\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return a_1, a_2, a_3\n",
    "\n",
    "def my_backward(l1, l2, l3, a_1, a_2, a_3, X_in, y_true):\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    dw_3, db_3, wdJdz_3 = l3.backward(dJdz_softmax(a_3,y_true),a_2)    # go through 3rd stage backward\n",
    "    dw_2, db_2, wdJdz_2 = l2.backward(dJdz_sigmoid(wdJdz_3,a_2),a_1)    # go through 2nd stage backward\n",
    "    dw_1, db_1, _       = l1.backward(dJdz_sigmoid(wdJdz_2,a_1),X_in)    # go through 1st stage backward\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    d_1 = [dw_1, db_1]\n",
    "    d_2 = [dw_2, db_2]\n",
    "    d_3 = [dw_3, db_3]\n",
    "    \n",
    "    return d_1, d_2, d_3\n",
    "\n",
    "def my_loss(l1, l2, l3, X_in, y_true):\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    _,_,a_3 = my_forward(l1,l2,l3,X_in)  # only last layer's forward output is necessary\n",
    "    loss = -(np.sum(y_true*np.log(a_3))) / X_in.shape[0]                 # calculate loss\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return loss\n",
    "    \n",
    "def my_predict(l1, l2, l3, X_in):\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    _,_,a_3 = my_forward(l1,l2,l3,X_in)           # only last layer's forward output is necessary\n",
    "    pred = np.argmax(a_3,axis=1)                  # make prediction\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a NN model and check the matrix dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DT0rMw-rTa5A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64) (1437, 10)\n",
      "(80, 64) (80,)\n",
      "(70, 80) (70,)\n",
      "(10, 70) (10,)\n"
     ]
    }
   ],
   "source": [
    "n_inputs  = 64\n",
    "n_hidden1 = 80\n",
    "n_hidden2 = 70\n",
    "n_classes = 10\n",
    "#customizing channel\n",
    "l1 = myDenseLayer(n_hidden1, n_inputs)\n",
    "l2 = myDenseLayer(n_hidden2, n_hidden1)\n",
    "l3 = myDenseLayer(n_classes, n_hidden2)\n",
    "#create layers\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(l1.wegt.shape, l1.bias.shape)\n",
    "print(l2.wegt.shape, l2.bias.shape)\n",
    "print(l3.wegt.shape, l3.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Outputs**\n",
    "\n",
    "```\n",
    "(1437, 64) (1437, 10)\n",
    "(80, 64) (80,)\n",
    "(70, 80) (70,)\n",
    "(10, 70) (10,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights are initialized to...\n",
    "l1.wegt = np.random.randn(n_hidden1, n_inputs)\n",
    "l2.wegt = np.random.randn(n_hidden2, n_hidden1)\n",
    "l3.wegt = np.random.randn(n_classes, n_hidden2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Simple Neural Network Model (3 layer model) (<b>Update weights</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55777,
     "status": "ok",
     "timestamp": 1649259680196,
     "user": {
      "displayName": "Seong-Won Lee",
      "userId": "14858304546124675216"
     },
     "user_tz": -540
    },
    "id": "qODinrZlTa5C",
    "outputId": "8237949a-964a-49cd-f3e9-fb65759245e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  500,  loss: 0.03429470\n",
      "Epoch: 1000,  loss: 0.01820917\n",
      "Epoch: 1500,  loss: 0.01581421\n",
      "Epoch: 2000,  loss: 0.01374552\n",
      "Epoch: 2500,  loss: 0.01224504\n",
      "Epoch: 3000,  loss: 0.00977645\n",
      "Epoch: 3500,  loss: 0.00750443\n",
      "Epoch: 4000,  loss: 0.00527477\n",
      "Epoch: 4500,  loss: 0.00162356\n",
      "Epoch: 5000,  loss: 0.00092371\n"
     ]
    }
   ],
   "source": [
    "# alpha: learning rate, lamda: regularization factor\n",
    "alpha = 0.01\n",
    "n_epochs = 5000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Forward Path\n",
    "    a_1, a_2, a_3 = my_forward(l1,l2,l3,X_train)   # forward path\n",
    "    \n",
    "    # Backward Path\n",
    "    d_1, d_2, d_3 = my_backward(l1,l2,l3,a_1,a_2,a_3,X_train,y_train)   # backward path\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    #save weight for update\n",
    "    dw_1, db_1 = d_1\n",
    "    dw_2, db_2 = d_2\n",
    "    dw_3, db_3 = d_3\n",
    "\n",
    "    # Update weights and biases\n",
    "    ### START CODE HERE ###\n",
    "    #each layer's weight and bias are updated with backpropagation\n",
    "    l3.wegt = l3.wegt - (alpha * dw_3)\n",
    "    l3.bias = l3.bias - (alpha * db_3)\n",
    "    l2.wegt = l2.wegt - (alpha * dw_2)\n",
    "    l2.bias = l2.bias - (alpha * db_2)\n",
    "    l1.wegt = l1.wegt - (alpha * dw_1) \n",
    "    l1.bias = l1.bias - (alpha * db_1)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print loss\n",
    "    if ((epoch+1)%500==0):\n",
    "        loss_J = my_loss(l1, l2, l3, X_train, y_train)\n",
    "        print('Epoch: %4d,  loss: %10.8f' % (epoch+1, loss_J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1649259686353,
     "user": {
      "displayName": "Seong-Won Lee",
      "userId": "14858304546124675216"
     },
     "user_tz": -540
    },
    "id": "xMvLn6SJTa5D",
    "outputId": "229cafc3-c9c5-4dd2-f7bc-d4cdf90c4d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472222222222222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = my_predict(l1, l2, l3, X_test) #prediction\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WieUxPz9Ta5F"
   },
   "source": [
    "Neural Network from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3086,
     "status": "ok",
     "timestamp": 1649259694763,
     "user": {
      "displayName": "Seong-Won Lee",
      "userId": "14858304546124675216"
     },
     "user_tz": -540
    },
    "id": "w8AcitiaTa5G",
    "outputId": "09455c7b-a58f-4492-b5cb-431eab436f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(80, 70, ), activation='logistic', solver='sgd', \\\n",
    "                    alpha=0.01, learning_rate_init=0.01, max_iter=1000)\n",
    "\n",
    "# Training/Fitting the Model\n",
    "mlp.fit(X_train, y_train_num)\n",
    "\n",
    "# Making Predictions\n",
    "s_pred = mlp.predict(X_test)\n",
    "accuracy_score(s_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmZQrDH9n0PK"
   },
   "source": [
    "### Test Model with a random sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My prediction is 2\n",
      "sk prediction is 2\n",
      "Actual number is 2\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(X_test.shape[0]) #display random sample\n",
    "dimage = X_test_org[idx].reshape((8,8)) #1D -> 2D\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.gray()\n",
    "plt.matshow(dimage, fignum=1)\n",
    "plt.show()\n",
    "\n",
    "X_input = np.expand_dims(X_test[idx], 0)\n",
    "\n",
    "y_pred = my_predict(l1, l2, l3, X_input)\n",
    "\n",
    "s_pred = mlp.predict(X_input)\n",
    "\n",
    "print('My prediction is ' + str(y_pred[0]))\n",
    "print('sk prediction is ' + str(s_pred[0]))\n",
    "print('Actual number is ' + str(y_test[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2024 SW Lee"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_L06_01_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "19c3f3f12223855b5e5811df3b51e2142b7f938327ffb9b9a66299337f7b60d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
